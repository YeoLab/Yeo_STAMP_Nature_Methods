{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import binom\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strand(df):\n",
    "    if (df['fwd'] > (df['rev'])*2):\n",
    "        return '+'\n",
    "    elif (df['rev'] > (df['fwd'])*2):\n",
    "        return '-'\n",
    "    else:\n",
    "        return '?'\n",
    "def edit_match(df):\n",
    "    if (df['strand']=='+'):\n",
    "        return (df['fwd_miss']/(df['fwd']+df['fwd_miss']))\n",
    "    elif (df['strand']=='-'):\n",
    "        return (df['rev_miss']/(df['rev']+df['rev_miss']))\n",
    "    else:\n",
    "        return '?'\n",
    "from scipy.special import betainc\n",
    "def mins(df):\n",
    "    if df['strand']=='+':\n",
    "        return  (1- betainc(df['fwd_miss'], df['fwd'], 0.05))\n",
    "    elif df['strand']==\"-\": \n",
    "        return (1- betainc(df['rev_miss'], df['rev'], 0.05))\n",
    "def total(df):\n",
    "    if df['strand']=='+':\n",
    "        return  (1- betainc(df['total_miss'], df['total_match'], 0.05))\n",
    "    elif df['strand']==\"-\": \n",
    "        return (1- betainc(df['total_miss'], df['total_match'], 0.05))\n",
    "    else:\n",
    "        return (1- betainc(df['total_miss'], df['total_match'], 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Import pileup files (Split by chromosome and filtered for C or G in reference position using awk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir= '/Path to directory containing GC filtered mpileups'\n",
    "beds = sorted(glob.glob(os.path.join(input_dir, '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a2a69be514ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m###Filters pileup files for C and G in reference position (redundant) then creates match and missmatch columns from I16 tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf_tmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf_tmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'G'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "###Filters pileup files for C and G in reference position (redundant) and read coverage 10 then creates match and missmatch columns from I16 tag\n",
    "###Concatenate chromosomes into single DF \n",
    "df=pd.DataFrame()\n",
    "for i in beds:\n",
    "    df_tmp=pd.read_csv(i,sep='\\t', header=None)\n",
    "    df_tmp=df_tmp[df_tmp[3].isin(['C','G'])]\n",
    "    df_tmp['DP']=list(map(lambda x: str(x).split(';')[0], df_tmp[7]))\n",
    "    df_tmp=df_tmp[df_tmp['DP']!=\"INDEL\"]\n",
    "    df_tmp['DP']=list(map(lambda x: str(x).split(';')[0].split('=')[1], df_tmp[7]))\n",
    "    df_tmp=df_tmp[df_tmp['DP'].astype(int)>=10]\n",
    "    df_tmp['fwd']=list(map(lambda x: str(x).split(';')[1].split('=')[1].split(',')[0], df_tmp[7]))\n",
    "    df_tmp['fwd_miss']=list(map(lambda x: str(x).split(';')[1].split('=')[1].split(',')[2], df_tmp[7]))\n",
    "    df_tmp['rev']=list(map(lambda x: str(x).split(';')[1].split('=')[1].split(',')[1], df_tmp[7]))\n",
    "    df_tmp['rev_miss']=list(map(lambda x: str(x).split(';')[1].split('=')[1].split(',')[3], df_tmp[7]))\n",
    "    df_tmp['DP']=df_tmp['DP'].astype(int)\n",
    "    df_tmp['fwd']=df_tmp['fwd'].astype(int)\n",
    "    df_tmp['fwd_miss']=df_tmp['fwd_miss'].astype(int)\n",
    "    df_tmp['rev']=df_tmp['rev'].astype(int)\n",
    "    df_tmp['rev_miss']=df_tmp['rev_miss'].astype(int)\n",
    "    df_tmp=df_tmp[df_tmp[3].isin(['G','C'])]\n",
    "    df=pd.concat([df,df_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Saves DF to csv for subsequent analysis (Save here to prevent loss if notebook crashes)\n",
    "df.to_csv('/Path to save directory/Filename.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Assigns strand based on read alignments\n",
    "df['strand'] = df.apply(strand, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculates edit fraction\n",
    "df['fraction_match'] = df.apply(edit_match, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get most common base mutation per site\n",
    "df['miss_base']=list(map(lambda x: str(x).split(',')[0], df[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['key']=df[0]+\":\"+df[1].astype(str)+\":\"+df['strand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Assign SAILOR confidence score per base WITH strand information (use for dRNA)\n",
    "df['confidence']=df.apply(mins, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Assign SAILOR confidence score per base WITHOUT strand info (use for cDNA)\n",
    "###Strand info will be gathered at the end of pipeline to reduce intersecting file size\n",
    "df['total_match']=df['fwd']+df['rev']\n",
    "df['total_miss']=df['fwd_miss']+df['rev_miss']\n",
    "df['total_fraction']=df['total_miss']/(df['total_miss']+df['total_match'])\n",
    "df['total_confidence']=df.apply(total, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Shift Base locations 0-based and Save (Use for subsequent notebooks)\n",
    "df[1]=df[1].astype(int)-1\n",
    "df['stop']=df[1].astype(int)+1\n",
    "df.to_csv('/Path to save directory/Filename.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Saves a temp. bedgraph file\n",
    "df[['0','1','stop','total_confidence']].to_csv('/Path to save directory/Sample_0.05_sailor.bedgraph', sep='\\t',header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
