{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates new epkm values for each cell barcode in ApoControl and RPS2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib_venn import venn2\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import gffutils\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_dir = '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA/sailor_outputs_individual_barcodes_merged_bedfiles'\n",
    "output_dir = '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA/sailor_outputs_individual_barcodes_merged_epkm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'cds'  # should match the suffix of the files that get created. Also controls the if/else statements below. Can be either cds, cds_and_3utr, or exons\n",
    "regions = ['CDS'] # ['CDS', '3utr']  # should line up with a region inside the annotated file\n",
    "replace = False  # this analysis takes counts data from two sources 1) 10X output for counting all exonic regions 2) featureCounts for counting CDS/CDS+3UTR regions, so the format is different. Mostly helps with formatting, see: convert_filename_to_barcode()\n",
    "rbp = 'Apo_Control'  # either Apo_Control, or RPS2\n",
    "gencode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA_APOBEC_RPS2/outputs/expression_counts/Apo_Control_possorted_genome_bam_MD-all_counts.cds_only.txt\n",
      "/home/bay001/projects/kris_apobec_20200121/permanent_data/20191003_riboseq/featurecounts/counts.cds_only.txt\n"
     ]
    }
   ],
   "source": [
    "if region == 'cds':\n",
    "    if rbp == 'RPS2':\n",
    "        counts_file = '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA_APOBEC_RPS2/outputs/expression_counts/RPS2_possorted_genome_bam_MD-all_counts.cds_only.txt'\n",
    "    else:\n",
    "        counts_file = '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA_APOBEC_RPS2/outputs/expression_counts/Apo_Control_possorted_genome_bam_MD-all_counts.cds_only.txt'\n",
    "    lengths_file = '/home/bay001/projects/kris_apobec_20200121/permanent_data/20191003_riboseq/featurecounts/counts.cds_only.txt'  # get the lengths of just CDS regions\n",
    "elif region == 'cds_and_3utr':\n",
    "    if rbp == 'RPS2':\n",
    "        counts_file = '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA_APOBEC_RPS2/outputs/expression_counts/RPS2_possorted_genome_bam_MD-all_counts.cds_and_3utr.txt'\n",
    "    else:\n",
    "        counts_file = '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA_APOBEC_RPS2/outputs/expression_counts/Apo_Control_possorted_genome_bam_MD-all_counts.cds_and_3utr.txt'\n",
    "    lengths_file = '/home/bay001/projects/kris_apobec_20200121/permanent_data/20191003_riboseq/featurecounts/counts.cds_and_3utr.txt'  # get the lengths of just CDS regions\n",
    "elif region == 'exons':\n",
    "    if rbp == 'RPS2':\n",
    "        counts_file = '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA/inputs/RPS2_filtered_feature_bc_matrix.csv'\n",
    "    else:\n",
    "        counts_file = '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA/inputs/Apo_Control_filtered_feature_bc_matrix.csv'\n",
    "    lengths_file = '/home/bay001/projects/kris_apobec_20200121/permanent_data/20191003_riboseq/featurecounts/counts.txt'  # get the lengths of all exons\n",
    "\n",
    "print(counts_file)\n",
    "print(lengths_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA/sailor_outputs_individual_barcodes_merged_bedfiles/Apo_Control_possorted_genome_bam_MD-AAACCCAAGCCAGTAG-1.fx.bed.annotated',\n",
       " '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA/sailor_outputs_individual_barcodes_merged_bedfiles/Apo_Control_possorted_genome_bam_MD-AAACCCAAGGATGCGT-1.fx.bed.annotated',\n",
       " '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA/sailor_outputs_individual_barcodes_merged_bedfiles/Apo_Control_possorted_genome_bam_MD-AAACCCACAATACAGA-1.fx.bed.annotated']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_annotated = sorted(glob.glob(os.path.join(annotated_dir, '{}*.annotated'.format(rbp))))\n",
    "print(len(all_annotated))\n",
    "all_annotated[:3]  # 19611 for all, 8616 for Apo, 10995 for RPS2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read gene counts\n",
    "- Just doing this once since it's a big file. We just need the total summed read counts across each cell, so I'll just write that to its own file and reference that instead of reading the counts every time."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# used this to get the counts across exons (from cellranger 10x matrices)\n",
    "counts_file = rps2_counts_file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "counts = pd.read_csv(\n",
    "    counts_file\n",
    ")\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "counts.set_index('Unnamed: 0', inplace=True)\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "read_counts = pd.DataFrame(counts.sum())\n",
    "read_counts.columns = ['read_counts']\n",
    "read_counts.to_csv(counts_file + \".readcounts.txt\", sep='\\t', header=True, index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# used this to get the read counts across CDS and CDS+3'UTR (from featureCounts)\n",
    "\n",
    "progress = tnrange(4) \n",
    "\n",
    "for counts_file in [\n",
    "    rps2_counts_cds_and_3utr_file,\n",
    "    rps2_counts_cds_file,\n",
    "    apo_counts_cds_and_3utr_file,\n",
    "    apo_counts_cds_file,\n",
    "]:\n",
    "    counts = pd.read_csv(\n",
    "        counts_file, index_col=0, sep='\\t'\n",
    "    )\n",
    "    print(counts.shape[0])\n",
    "    read_counts = pd.DataFrame(counts.sum())\n",
    "    read_counts.columns = ['read_counts']\n",
    "    read_counts.to_csv(counts_file + \".readcounts.txt\", sep='\\t', header=True, index=True)\n",
    "    progress.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute epkm:\n",
    "- (# of Edited Counts (from SAILOR)) / ((total mapped read counts/10^6)*(Gene length/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edited_reads</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensembl_geneid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000087086</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000089009</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000096384</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000101182</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000104529</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 edited_reads\n",
       "ensembl_geneid               \n",
       "ENSG00000087086             1\n",
       "ENSG00000089009             1\n",
       "ENSG00000096384             2\n",
       "ENSG00000101182             2\n",
       "ENSG00000104529             8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_names = ['chrom','start','end','conf','cov','strand','geneid','genename','region','overlap']\n",
    "\n",
    "def read_and_sum_edits(f, regions=regions, gencode=True):\n",
    "    edits = pd.read_csv(f, sep='\\t', names=annotated_names)\n",
    "    del edits['overlap']\n",
    "    edits = edits[edits['region'].isin(regions)]\n",
    "    edits = edits.loc[edits.geneid.apply(lambda x: len(x.split(','))) == 1] # removing ambiguous editing events (more than one gene)\n",
    "    edits['edited_reads'] = edits['cov'].apply(lambda x: int(x.split(',')[0]))\n",
    "    if not gencode:\n",
    "        edits.reset_index(inplace=True)\n",
    "        edits['ensembl_geneid'] = edits['geneid'].apply(lambda x: x.split('.')[0])\n",
    "        del edits['geneid']\n",
    "        edits.set_index('ensembl_geneid', inplace=True)\n",
    "        return pd.DataFrame(edits.groupby('ensembl_geneid')['edited_reads'].sum())\n",
    "    return pd.DataFrame(edits.groupby('geneid')['edited_reads'].sum())\n",
    "# testing\n",
    "read_and_sum_edits(f=all_annotated[0], gencode=gencode).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edited_reads    38\n",
       "Name: ENSG00000144713, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one more test\n",
    "test_annotated_file = '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA/sailor_outputs_individual_barcodes_merged_bedfiles/RPS2_possorted_genome_bam_MD-GTAACCAAGTGAATAC-1.fx.bed.annotated'\n",
    "read_and_sum_edits(f=test_annotated_file, gencode=gencode).loc['ENSG00000144713']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apo_Control_possorted_genome_bam_MD-AAACCCAAGCCAGTAG-1.bam</th>\n",
       "      <td>16998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apo_Control_possorted_genome_bam_MD-AAACCCAAGGATGCGT-1.bam</th>\n",
       "      <td>24143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apo_Control_possorted_genome_bam_MD-AAACCCACAATACAGA-1.bam</th>\n",
       "      <td>14618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apo_Control_possorted_genome_bam_MD-AAACCCACACGCAGTC-1.bam</th>\n",
       "      <td>23624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apo_Control_possorted_genome_bam_MD-AAACCCACAGAACATA-1.bam</th>\n",
       "      <td>18494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    read_counts\n",
       "Apo_Control_possorted_genome_bam_MD-AAACCCAAGCC...        16998\n",
       "Apo_Control_possorted_genome_bam_MD-AAACCCAAGGA...        24143\n",
       "Apo_Control_possorted_genome_bam_MD-AAACCCACAAT...        14618\n",
       "Apo_Control_possorted_genome_bam_MD-AAACCCACACG...        23624\n",
       "Apo_Control_possorted_genome_bam_MD-AAACCCACAGA...        18494"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These should be the read counts across the specified genomic regions (either all exons, CDS only, or CDS + 3'UTR)\n",
    "read_counts = pd.read_csv(counts_file + \".readcounts.txt\", sep='\\t', index_col=0)\n",
    "read_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apo_Control_possorted_genome_bam_MD-AAACCCAAGCCAGTAG-1.bam'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_filename_to_barcode(f, replace=True):\n",
    "    \"\"\"\n",
    "    replace: True if we are using all exons (due to the different format of mtx file). False if we're using a merged featureCounts file (which we used when counting CDS and CDS+3'UTR reads)\n",
    "    \"\"\"\n",
    "    if replace:\n",
    "        return f.replace(\n",
    "            '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA/sailor_outputs_individual_barcodes_merged_bedfiles/Apo_Control_possorted_genome_bam_MD-',''\n",
    "        ).replace(\n",
    "            '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA/sailor_outputs_individual_barcodes_merged_bedfiles/RPS2_possorted_genome_bam_MD-',''\n",
    "        ).replace(\n",
    "            '.fx.bed.annotated',''\n",
    "        )\n",
    "    else:\n",
    "        return f.replace(\n",
    "            '/home/bay001/projects/kris_apobec_20200121/permanent_data2/03_scRNA/sailor_outputs_individual_barcodes_merged_bedfiles/',''\n",
    "        ).replace(\n",
    "            '.fx.bed.annotated',''\n",
    "        ) + '.bam'\n",
    "# testing\n",
    "convert_filename_to_barcode(all_annotated[0], replace=replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16998"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_read_counts_from_barcode(barcode, read_counts=read_counts):\n",
    "    return read_counts.loc[barcode]['read_counts']\n",
    "\n",
    "# testing\n",
    "get_read_counts_from_barcode(convert_filename_to_barcode(all_annotated[0], replace=replace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to get the gene lengths from somewhere, let's just use the lengths from a featureCounts output that we've run before.\n",
    "- we can use different lengths if we're calculating the EPKM across CDS only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geneid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000186092</th>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000237683</th>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000235249</th>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000185097</th>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000269831</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Length\n",
       "Geneid                 \n",
       "ENSG00000186092     915\n",
       "ENSG00000237683     777\n",
       "ENSG00000235249     936\n",
       "ENSG00000185097     936\n",
       "ENSG00000269831     129"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = pd.read_csv(\n",
    "    lengths_file,\n",
    "    index_col=0,\n",
    "    skiprows=1,\n",
    "    sep='\\t'\n",
    ")[['Length']]\n",
    "lengths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epkm(row, total_mapped, colname):\n",
    "    edit_counts = row[colname]\n",
    "    return edit_counts/((total_mapped/1000000.)*(row['Length']/1000.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21de40acb2fa4d0b9fe008870337294b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8616), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress = tnrange(len(all_annotated))\n",
    "\n",
    "for annotated in all_annotated:\n",
    "    output_file = os.path.join(output_dir, os.path.basename(annotated) + \".{}.epkm.tsv\".format(region))\n",
    "    if not os.path.exists(output_file):\n",
    "        edit_counts = read_and_sum_edits(f=annotated, gencode=gencode)\n",
    "        total_mapped = get_read_counts_from_barcode(convert_filename_to_barcode(annotated, replace=replace))\n",
    "\n",
    "        read_edit_counts = pd.merge(lengths, edit_counts, how='left', left_index=True, right_index=True).fillna(0)\n",
    "        read_edit_counts['epkm'] = read_edit_counts.apply(epkm, axis=1, args=(total_mapped, 'edited_reads'))\n",
    "        read_edit_counts.to_csv(\n",
    "            output_file, \n",
    "            sep='\\t'\n",
    "        )\n",
    "    progress.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3essential (tscc)",
   "language": "python",
   "name": "python3essential"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
